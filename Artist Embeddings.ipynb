{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for Artist Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex2id(hex):\n",
    "    return df.id[df.artist_id==hex].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_similar_artistx = {hex2id(i):set() for i in tqdm.tqdm(final_all_artists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "for i in tqdm.tqdm(similar_all_artists.items()):\n",
    "    for sim_ar in i[1]:\n",
    "        id_similar_artistx[hex2id(i[0])].add(hex2id(sim_ar))\n",
    "        id_similar_artistx[hex2id(sim_ar)].add(hex2id(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(id_similar_artistx, open('id_similar_artists.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simar = [list(i[1]) for i in id_similar_artistx.items()]\n",
    "\n",
    "df_train = pd.DataFrame({\"rated\":simar})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"matches_train_for_d2v.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "np.random.seed(0)\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "class ModelSaver(CallbackAny2Vec):\n",
    "    \"\"\"Gensim callback to save model every log_frequency epochs\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, d2v_object, rated_embeddings_path, w2v_model_path, log_frequency=5\n",
    "    ):\n",
    "        self.epoch = 1\n",
    "        self.log_frequency = log_frequency\n",
    "        self.d2v_object = d2v_object\n",
    "        self.rated_embeddings_path = rated_embeddings_path\n",
    "        self.w2v_model_path = w2v_model_path\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        if self.epoch % self.log_frequency == 0:\n",
    "            self.d2v_object.w2v_model = model\n",
    "            self.d2v_object.wv = model.wv\n",
    "            self.d2v_object.save_rated_vec(self.rated_embeddings_path)\n",
    "            self.d2v_object.save_w2v_model(self.w2v_model_path)\n",
    "        self.epoch += 1\n",
    "\n",
    "\n",
    "class D2V_Recommender:\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size=100,\n",
    "        window=3,\n",
    "        min_count=1,\n",
    "        workers=multiprocessing.cpu_count() - 1,\n",
    "        num_epochs=50,\n",
    "        sample=0,  # do not downsample\n",
    "    ):\n",
    "        self.embedding_size = embedding_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers\n",
    "        self.num_epochs = num_epochs\n",
    "        self.sample = sample\n",
    "\n",
    "        self.wv = None\n",
    "        self.mean_embeddings = (\n",
    "            # access to embeddings with self.mean_embeddings[\"rater_user_id\"]\n",
    "            None\n",
    "        )\n",
    "        self.data_dict = None  # dict of arrays with X_train, X_test, y_train, y_test\n",
    "\n",
    "    def fit_rated_embeddings(\n",
    "        self, d2v_train, w2v_model_path, rated_embeddings_path, resume_training=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fit and save Word2Vec model to embed rated users based on dating behavior of raters.\n",
    "\n",
    "        :param d2v_train: A pd.Series of list of rated_ids (string) that were co-liked by a rater\n",
    "        \"\"\"\n",
    "        # Prepare the data iterator\n",
    "        d2v_train_iterator = self.build_data_iterator(d2v_train)\n",
    "\n",
    "        # Initiate the model\n",
    "        \n",
    "        model_saver = ModelSaver(self, rated_embeddings_path, w2v_model_path)\n",
    "        self.w2v_model = Word2Vec(\n",
    "            vector_size=self.embedding_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=self.workers,\n",
    "            sample=self.sample,\n",
    "            sg=1,  # skip-gram\n",
    "            hs=0,\n",
    "            negative=5,\n",
    "            callbacks=[model_saver],\n",
    "            seed=0,\n",
    "        )\n",
    "        model = self.w2v_model\n",
    "        if resume_training:\n",
    "            model = self.load_w2v_model(w2v_model_path)\n",
    "            model.build_vocab(d2v_train_iterator, update=True)\n",
    "        elif model.train_count == 0:\n",
    "            model.build_vocab(d2v_train_iterator)\n",
    "\n",
    "        # train and save final model\n",
    "        model.train(\n",
    "            d2v_train_iterator,\n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=self.num_epochs,\n",
    "            compute_loss=True,\n",
    "        )\n",
    "\n",
    "        self.w2v_model = model\n",
    "        self.wv = model.wv\n",
    "        self.save_rated_vec(rated_embeddings_path)\n",
    "        self.save_w2v_model(w2v_model_path)\n",
    "\n",
    "    def build_data_iterator(self, data):\n",
    "        \"\"\" Create an iterator of which an iter is random passes on the data\"\"\"\n",
    "\n",
    "        class shuffle_generator:\n",
    "            def __init__(self, data):\n",
    "                self.data = data\n",
    "\n",
    "            def __iter__(self):\n",
    "                self.data.apply(np.random.shuffle)\n",
    "                return shuffle_generator_iter(self.data)\n",
    "\n",
    "        class shuffle_generator_iter:\n",
    "            def __init__(self, data):\n",
    "                self.i = 0\n",
    "                self.data = data\n",
    "                self.data_length = len(data)\n",
    "\n",
    "            def __iter__(self):\n",
    "                # Iterators are iterables too.\n",
    "                # Adding this functions to make them so.\n",
    "                return self\n",
    "\n",
    "            def __next__(self):\n",
    "                if self.i < 5 * self.data_length:\n",
    "                    # Shuffle at the end of the data\n",
    "                    if self.i % self.data_length == 0:\n",
    "                        self.data.apply(np.random.shuffle)\n",
    "                    i = self.i\n",
    "                    self.i += 1\n",
    "                    return self.data[i % self.data_length]  # a list\n",
    "                else:\n",
    "                    raise StopIteration()\n",
    "\n",
    "        return shuffle_generator(data)\n",
    "\n",
    "    def get_single_rated_vec(self, rated_id):\n",
    "        \"\"\" Get embedding vector of rated user of id rated_id\"\"\"\n",
    "        try:\n",
    "            return self.wv[str(rated_id)]\n",
    "        except KeyError:\n",
    "            # The rated user did not appear in the training dataset\n",
    "            return None\n",
    "\n",
    "    def get_single_rater_vec(self, rater_id):\n",
    "        \"\"\" Get embedding vector of rater user of id rater_id\"\"\"\n",
    "        try:\n",
    "            return self.mean_embeddings.loc[str(rater_id)].values\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "    def save_rated_vec(self, wordvectors_path):\n",
    "        # wordvectors_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.wv.save(str(wordvectors_path))\n",
    "\n",
    "    def load_rated_vec(self, wordvectors_path):\n",
    "        self.wv = KeyedVectors.load(str(wordvectors_path), mmap=\"r\")\n",
    "        return self.wv\n",
    "\n",
    "    def save_w2v_model(self, w2v_model_path):\n",
    "        # w2v_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.w2v_model.save(str(w2v_model_path))\n",
    "\n",
    "    def load_w2v_model(self, w2v_model_path):\n",
    "        self.w2v_model = Word2Vec.load(str(w2v_model_path), mmap=\"r\")\n",
    "        return self.w2v_model\n",
    "\n",
    "    def save_data_dict(self, data_dict_path):\n",
    "        with open(data_dict_path, \"wb\") as handle:\n",
    "            pickle.dump(self.data_dict, handle,\n",
    "                        protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load_data_dict(self, data_dict_path):\n",
    "        with open(data_dict_path, \"rb\") as handle:\n",
    "            self.data_dict = pickle.load(handle)\n",
    "        return self.data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    return [str(i) for i in x]\n",
    "    \n",
    "recommender = D2V_Recommender()\n",
    "\n",
    "d2v_train = df_train[\"rated\"].map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_training = False\n",
    "recommender.fit_rated_embeddings(\n",
    "    d2v_train,\n",
    "    \"model.bin\",\n",
    "    \"rated.vectors\",\n",
    "    resume_training=resume_training,\n",
    ")\n",
    "del d2v_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recommender.wv.index_to_key)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
